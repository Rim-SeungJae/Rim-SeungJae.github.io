---

title: 해양 침적 쓰레기 이미지를 활용한 인공지능 프로젝트

date: 2024-01-11 16:00:00 +09:00

categories: [프로젝트,인공지능]

tags: [프로젝트,인공지능,AI,이미지분류]

---
---
## 개요
본 프로젝트에는 AI-Hub의 [해양 침적 쓰레기 이미지 데이터셋](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=236)이 사용되었다. 해당 데이터셋은 해양 침적 쓰레기의 수거를 위해 실시, 설계 조사를 보다 빠르고 효율적으로 수행하고자 조사 과정에서 생성되는 소나 조사 이미지와 수중 촬영 이미지를 통해 침적 쓰레기를 자동 인식하고 분류할 수 있도록 인공지능을 훈련하기 위한 데이터셋이다.

우리는 해당 데이터셋의 선행 프로젝트에서 인공지능 모델로 YOLO를 선택했음에 주목했다. YOLO는 특정 이미지에서 여러가지 대상들이 각각 어떤 사물인지, 그리고 이미지 내에서 어느 위치에 있는지 탐지해내는 multi-label object detection 측면에서 강력하기로 유명한 모델이다.

그러나 해당 데이터셋의 이미지들을 분석해보면 한 이미지 내에 여러가지 쓰레기들이 혼재하는 경우는 매우 드물다는 점을 알 수 있다. 그러므로 YOLO 정도로 complex한 모델이 오히려 불필요할 수도 있다는 가능성을 도출하였다. 따라서 이번 프로젝트에서는 YOLO보다 가벼운 cnn 관련 모델들을 여러개 구현하여 각각의 성능을 비교해보고자 한다.

| ![bundle of ropes_004_03833](https://github.com/Rim-SeungJae/2021-03-11-OSS/assets/50349104/c16208ee-2eec-457b-9726-89ce39811449) |
|:--:|
|해양 쓰레기 '밧줄'이 포함된 데이터 샘플|

---
## 사용한 모델들
본 프로젝트에서 해양 침적 쓰레기 이미지 분류를 위해 구현된 모델은 총 4가지이다.

1) VGGNet

VGGNet은 심층 신경망의 시작점이라고도 많이 불리는 모델이다. VGGNet이 등장하기 이전, ImageNet Large Scale Visual Recognition Challenge에서 우수한 성적을 거두었던 모델들은 최대 8개 층을 이용했다.다른 수많은 모델들이 VGGNet의 영향을 받았다는 점을 고려하면 본 프로젝트에서 VGGNet을 기용하는 것은 충분히 의미가 있다.

| ![vggnet](https://pytorch.org/assets/images/vgg.png) |
|:--:|
|VGGNet의 구조|

2) ResNet

ResNet은 "Deep Residual Learning for Image"에서 처음 소개된 모델이다. ResNet의 가장 큰 특징은 3x3 크기의 컨볼루션 레이어만 사용하여 이미지의 특성을 추출한다는 점이다. 우리 프로젝트에서는 ResNet의 가장 기본적인 형태인 ResNet-18을 사용한다.

| ![resnet](https://www.researchgate.net/profile/Paolo-Napoletano/publication/322476121/figure/tbl1/AS:668726449946625@1536448218498/ResNet-18-Architecture.png) |
|:--:|
|ResNet-18의 구조|

3) DenseNet

DenseNet은 2017년에 등장했다. DenseNet은 ResNet을 이기기 위해 개발된 것으로 둘 간에는 몇 가지 차이가 존재한다. 'Densely Connected Convolutional Networks' 논문에 따르면 DenseNet은 기울기 소실 문제를 해결하고 강한 기울기 흐름과 정보 흐름을 가진 특성 재사용 능력이 있다고 한다.

| ![resnet](https://pytorch.org/assets/images/densenet2.png) |
|:--:|
|DenseNet의 구조|

4) DarkNet

DarkNet은 YOLO 버전 2와 3의 백본 모델이다. 그 구조는 GoogleNet과 매우 유사하지만 1x1 컨볼루션 레이어를 사용한다. ImageNet에서의 결과를 참고하면 DarkNet은 레이어 수에 비해 매우 높은 정확도를 기록한다.DarkNet을 프로젝트에 사용하는 또 다른 이유는 이것이 YOLO 모델들의 백본이기 때문이다. 앞서 언급한거처럼 YOLO 전체를 해양 침적 쓰레기 데이터셋에 적용하는것은 비효율적인 것처럼 보이지만 YOLO의 백본인 DarkNet만을 활용한다면 더 좋은 결과를 얻을지도 모른다.

| ![resnet](https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-24_at_12.38.12_PM.png) |
|:--:|
|DarkNet-19의 구조|

---
## 결과

| 모델       | 정확도 |
|------------|--------|
| ResNet     | 55%    |
| DarkNet    | 21%    |
| VGGNet     | 50%    |
| DenseNet   | 43%    |

DenseNet은 모델 복잡성이 높은 편인데도 VGGNet 및 ResNet보다 정확도가 낮다. 특히, 모델 복잡성이 가장 높은 DarkNet은 정확도가 21%로 급격하게 감소한다. 이는 과제에 대한 우리의 해석이 어느 정도 옳았음을 증명한다. 처음에 우리는 YOLO와 같은 고수준의 object detection 모델이 필요하지 않을 것으로 생각했다. 따라서 우리는 이 과제를 4개의 모델을 사용한 multi-label 분류 문제로 접근했다. 결론적으로 DenseNet과 DarkNet의 complexity가 이 작업을 수행하기에 너무 높아서 훈련 데이터에서 과적합이 발생하면서 정확도가 낮아졌다고 볼 수 있는 것이다.

그러나 아쉬운점은 우리 모델 중 가장 높은 정확도가 55%에 불과하다는 점이다. 개발 환경에서의 컴퓨팅 파워 제한으로 인한 불가피한 이미지 크기의 조정, 그리고 학습 데이터셋 크기가 크지 않다는 사실이 영향을 미쳤을 것이라고 추측한다.

---
## 프로젝트 링크
| :link:  [프로젝트 깃허브 링크](https://github.com/Rim-SeungJae/AI_Project_team5)  |

---
## 프로젝트 참여자
| :link:  [Rim-SeungJae](https://github.com/Rim-SeungJae)  |
| :link:  [DongwonKim](https://github.com/dongwon18)  |